{
 "cells": [
  {
   "cell_type": "code",
   "id": "79551282a624bc61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:46:15.943096Z",
     "start_time": "2024-11-08T20:46:15.938215Z"
    }
   },
   "source": [
    "import nltk\n",
    "import re\n",
    "import requests\n",
    "import string\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WhitespaceTokenizer, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "id": "4ff83926ee4e455b",
   "metadata": {},
   "source": [
    "1. Download Alice in Wonderland"
   ]
  },
  {
   "cell_type": "code",
   "id": "e729fedfef78a97a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:46:17.182461Z",
     "start_time": "2024-11-08T20:46:16.113505Z"
    }
   },
   "source": [
    "url = \"http://www.gutenberg.org/files/11/11-0.txt\"\n",
    "response = requests.get(url)\n",
    "text = response.text"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "id": "9b328586-15fe-49ff-b764-7e45a0d81e46",
   "metadata": {},
   "source": [
    "2. Perform any necessary preprocessing on the text, including converting to lower case, removing stop words, numbers / non-alphabetic characters, lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "id": "10d155e8-ecf1-4659-b774-516ac4214b1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:46:17.192086Z",
     "start_time": "2024-11-08T20:46:17.185473Z"
    }
   },
   "source": [
    "def preprocessing(text: str) -> str:\n",
    "\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special character\n",
    "    \n",
    "    # Remove non-alphabetic characters\n",
    "    # text = re.sub(r'[^a-z\\s\\.]', '', text)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = WhitespaceTokenizer().tokenize(text)\n",
    "\n",
    "    # Lemmatize the text\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # stemmer = PorterStemmer()\n",
    "    text = ' '.join([lemmatizer.lemmatize(token) for token in tokens])\n",
    "    # text = ' '.join([stemmer.stem(token) for token in tokens])\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words and len(word) > 1])\n",
    "    \n",
    "    return text.replace('_', '').strip()"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "2e24d060-0621-4a87-8d30-f5d33e6190a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:46:17.345067Z",
     "start_time": "2024-11-08T20:46:17.193096Z"
    }
   },
   "source": [
    "text = preprocessing(text)"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "id": "887201af-7264-488a-ba3d-3f0f1603f224",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:46:17.352401Z",
     "start_time": "2024-11-08T20:46:17.346077Z"
    }
   },
   "source": [
    "len(text.split('chapter'))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "id": "42f86685-dde3-48ce-b428-d937c62aead4",
   "metadata": {},
   "source": [
    "3. Find Top 10 most important (for example, in terms of TF-IDF metric) words from each chapter in the text (not \"Alice\"); how would you name each chapter according to the identified tokens?"
   ]
  },
  {
   "cell_type": "code",
   "id": "a8e53477-defb-42d8-8ea9-7688d75f3bbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:46:17.368375Z",
     "start_time": "2024-11-08T20:46:17.352401Z"
    }
   },
   "source": [
    "chapter_pattern = r\"chapter\\s+\\w+\"\n",
    "chapters = re.split(chapter_pattern, text, flags=re.IGNORECASE)\n",
    "chapters = chapters[13:]\n",
    "# chapters = list(map(lambda x: x.strip(), chapters))"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "id": "ae861842-a87a-490c-a35e-c4c7ca81921e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:46:17.374698Z",
     "start_time": "2024-11-08T20:46:17.369386Z"
    }
   },
   "source": "tfidf_vectorizer = TfidfVectorizer(stop_words='english')",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:46:17.399360Z",
     "start_time": "2024-11-08T20:46:17.375704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## FIXED ROW\n",
    "tfs = tfidf_vectorizer.fit_transform(chapters)"
   ],
   "id": "4af67fb99a2bc9a4",
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "id": "69ae1c47-c96d-4644-9b45-c4576a329ae3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:46:17.449299Z",
     "start_time": "2024-11-08T20:46:17.400369Z"
    }
   },
   "source": [
    "chapters_dict = {}\n",
    "for chapter_num, chapter in tqdm(enumerate(chapters)):\n",
    "    ### FIXED ROW BELOW\n",
    "    tfidf_matrix = tfidf_vectorizer.transform([chapter])\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    top_words = sorted(zip(feature_names, tfidf_matrix.toarray()[0]), key=lambda x: x[1], reverse=True)[:11]\n",
    "    chapters_dict[chapter_num + 1] = \", \".join([word for index, (word, score) in enumerate(top_words)\n",
    "                                                         if word != 'alice' and index < 11])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 295.64it/s]\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "id": "c9f1c3f6-bbf6-4bab-ba54-063c6ff1070f",
   "metadata": {},
   "source": [
    "Hello!\n",
    "Here almost all the chapters contain the words \"said\" and \"wa\", this is incorrect, since in the tf-idf approach the weight of words that are contained in all chapters should decrease. \n",
    "\n",
    "First, fit all chapters to the model, second, sequentially transform the text for chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2200ba8-f0b0-428e-ac69-208196e393fd",
   "metadata": {},
   "source": [
    "Honestly, my fantasy is working not so good, but I've tried to name the chapters.\n",
    "\n",
    "1. Thinking was like litte\n",
    "2. Oh, mouse was little\n",
    "3. Mouse said dodo\n",
    "4. There was one little rabbit\n",
    "5. Caterpillar, pigeon, serpent\n",
    "6. Duchees Cat\n",
    "7. Dormouse Hatter\n",
    "8. Queen and King\n",
    "9. Mock Turtle\n",
    "10. Gryphon Turtle\n",
    "11. King Hatter\n",
    "12. King likes jury"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9d1b20-c464-452a-af49-fff97d2baf31",
   "metadata": {},
   "source": [
    "4. Find the Top 10 most used verbs in sentences with Alice"
   ]
  },
  {
   "cell_type": "code",
   "id": "3c9fee0a-76f5-46eb-b833-4c8951833e4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:46:17.485958Z",
     "start_time": "2024-11-08T20:46:17.457190Z"
    }
   },
   "source": [
    "sentences = sent_tokenize(text)"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "id": "c134e7fe-72a0-4db7-a350-7387be7583e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:46:18.582503Z",
     "start_time": "2024-11-08T20:46:17.487632Z"
    }
   },
   "source": [
    "url = \"http://www.gutenberg.org/files/11/11-0.txt\"\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "sentences = sent_tokenize(text)"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "id": "9ddde7c9-ba20-45d2-884b-707d7bec3a41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:46:18.971870Z",
     "start_time": "2024-11-08T20:46:18.584513Z"
    }
   },
   "source": [
    "sentences = list(map(preprocessing, sentences))    \n",
    "sentences = list(map(lambda x: x.replace('.', ' '), sentences))    "
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "id": "35f2e8da-5ad1-470f-ba1e-e1ec73eb0303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:46:18.976821Z",
     "start_time": "2024-11-08T20:46:18.972883Z"
    }
   },
   "source": [
    "alice_sentences = [sentence for sentence in sentences if 'alice' in sentence.lower()]"
   ],
   "outputs": [],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "id": "4d70c2ef-4e32-4011-84c9-8b88072b8470",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:46:18.992842Z",
     "start_time": "2024-11-08T20:46:18.977871Z"
    }
   },
   "source": [
    "verb_counts = Counter()"
   ],
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "id": "db9a495a-06be-46fb-b754-bdf8d50e4cda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:46:19.486522Z",
     "start_time": "2024-11-08T20:46:18.993850Z"
    }
   },
   "source": [
    "for sentence in alice_sentences:\n",
    "    for word, tag in nltk.pos_tag(sentence.split()):\n",
    "        if tag in ['VB', 'VBP']:\n",
    "            verb_counts[word] += 1\n",
    "\n",
    "top_verbs = verb_counts.most_common(10)"
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "id": "8bf3ccdf-d9fe-4e16-af1b-7c99cc3ae297",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T20:46:19.492736Z",
     "start_time": "2024-11-08T20:46:19.487531Z"
    }
   },
   "source": [
    "top_verbs"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('say', 35),\n",
       " ('know', 32),\n",
       " ('go', 27),\n",
       " ('see', 23),\n",
       " ('think', 21),\n",
       " ('get', 17),\n",
       " ('make', 15),\n",
       " ('come', 14),\n",
       " ('take', 12),\n",
       " ('wa', 11)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "id": "811653b0-39ec-4aa3-a370-2ffcd08636f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T19:56:35.653147Z",
     "start_time": "2024-10-20T19:56:35.651668Z"
    }
   },
   "source": [
    "What does Alice do most often?\n",
    "\n",
    "Alice thinks, knows, says, goes, and sees."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
